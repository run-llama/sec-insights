services:
  llama-app-fastapi:
    build:
      context: .
    volumes:
      # allows for live reloading of the app
      # when the code within the ./app directory changes
      - ./:/app
    ports:
      - "127.0.0.1:8000:8000"
    depends_on:
      - db
    env_file:
      - .env
      - .env.docker
    environment:
      BACKEND_CORS_ORIGINS: '["http://localhost", "http://localhost:8000"]'

  db:
    image: ankane/pgvector:v0.5.0
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: llama_app_db
    ports:
      - "127.0.0.1:5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data/

  localstack:
    container_name: "${LOCALSTACK_DOCKER_NAME-localstack_main}"
    image: localstack/localstack
    ports:
      - "127.0.0.1:4566:4566" # LocalStack Gateway
      - "127.0.0.1:4510-4559:4510-4559" # external services port range
    environment:
      - DEBUG=${DEBUG-}
      - DOCKER_HOST=unix:///var/run/docker.sock
    volumes:
      - "${LOCALSTACK_VOLUME_DIR:-./volume}:/var/lib/localstack"
      - "/var/run/docker.sock:/var/run/docker.sock"

volumes:
  postgres_data:
